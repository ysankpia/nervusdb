import { readPagedManifest } from '../storage/pagedIndex.js';
import { promises as fsp } from 'node:fs';
import {
  compactDatabase,
  type CompactOptions,
  type CompactStats,
  type IndexOrder,
} from './compaction.js';
import { readHotness } from '../storage/hotness.js';
import { garbageCollectPages } from './gc.js';

export interface AutoCompactOptions {
  orders?: IndexOrder[];
  minMergePages?: number;
  tombstoneRatioThreshold?: number;
  pageSize?: number;
  compression?: { codec: 'none' | 'brotli'; level?: number };
  hotCompression?: { codec: 'none' | 'brotli'; level?: number };
  coldCompression?: { codec: 'none' | 'brotli'; level?: number };
  dryRun?: boolean;
  mode?: 'rewrite' | 'incremental';
  hotThreshold?: number; // çƒ­ä¸»é”®é˜ˆå€¼ï¼Œä»…å¢é‡æ¨¡å¼ç”Ÿæ•ˆ
  maxPrimariesPerOrder?: number; // æ¯ä¸ªé¡ºåºæœ€å¤šé‡å†™çš„ primary æ•°
  autoGC?: boolean; // æ‰§è¡Œåè‡ªåŠ¨ GC
  scoreWeights?: { hot?: number; pages?: number; tomb?: number }; // å¤šå› ç´ è¯„åˆ†æƒé‡ï¼ˆé»˜è®¤ hot=1,pages=1,tomb=0.5ï¼‰
  minScore?: number; // æ»¡è¶³åˆ†æ•°é˜ˆå€¼æ‰çº³å…¥å€™é€‰ï¼ˆé»˜è®¤ 1ï¼‰
  respectReaders?: boolean; // å½“å­˜åœ¨è¯»è€…æ—¶è·³è¿‡ï¼ˆè·¨è¿›ç¨‹å¯è§ï¼‰
  includeLsmSegments?: boolean; // å°† LSM æ®µå¹¶å…¥ compaction å¹¶æ¸…ç†
  includeLsmSegmentsAuto?: boolean; // è‡ªåŠ¨è¯„ä¼°æ˜¯å¦å¹¶å…¥ LSM æ®µ
  lsmSegmentsThreshold?: number; // è§¦å‘å¹¶å…¥çš„æ®µæ•°é‡é˜ˆå€¼ï¼ˆé»˜è®¤ 1ï¼‰
  lsmTriplesThreshold?: number; // è§¦å‘å¹¶å…¥çš„æ®µä¸‰å…ƒç»„æ•°é‡é˜ˆå€¼ï¼ˆé»˜è®¤ pageSize æˆ– 1024ï¼‰
}

export interface AutoCompactDecision {
  selectedOrders: IndexOrder[];
  compact?: CompactStats;
  skipped?: boolean;
  reason?: string;
  readers?: number;
}

export async function autoCompact(
  dbPath: string,
  options: AutoCompactOptions = {},
): Promise<AutoCompactDecision> {
  // é»˜è®¤å¹²è·‘ï¼ˆä¸æ”¹ç£ç›˜ï¼‰ï¼Œä¸ CLI æ–‡æ¡£ä¸€è‡´ï¼›éœ€è¦çœŸå®æ‰§è¡Œæ—¶æ˜¾å¼ä¼  dryRun: false
  const dryRun = options.dryRun ?? true;
  console.log(`ğŸ”§ Starting auto-compact analysis for: ${dbPath}`);
  console.log(`   Mode: ${options.mode ?? 'incremental'}`);
  console.log(`   Min merge pages: ${options.minMergePages ?? 2}`);
  console.log(`   Dry run: ${dryRun}`);

  const manifest = await readPagedManifest(`${dbPath}.pages`);
  if (!manifest) {
    console.log(`âŒ No paged manifest found`);
    return { selectedOrders: [] };
  }

  console.log(`ğŸ“Š Manifest summary:`);
  console.log(`   Total lookups: ${manifest.lookups.length}`);
  console.log(`   Page size: ${manifest.pageSize}`);
  console.log(`   Tombstones: ${manifest.tombstones?.length ?? 0}`);

  if (options.respectReaders) {
    try {
      const { getActiveReaders } = await import('../storage/readerRegistry.js');
      const readers = await getActiveReaders(`${dbPath}.pages`);
      if (readers.length > 0) {
        console.log(`ğŸ”’ Skipping compaction due to ${readers.length} active readers`);
        return {
          selectedOrders: [],
          skipped: true,
          reason: 'active_readers',
          readers: readers.length,
        };
      } else {
        console.log(`âœ… No active readers found - proceeding with compaction`);
      }
    } catch {
      console.log(`âš ï¸  Failed to check active readers - proceeding anyway`);
    }
  }

  const orders: IndexOrder[] = options.orders ?? ['SPO', 'SOP', 'POS', 'PSO', 'OSP', 'OPS'];
  const minMergePages = options.minMergePages ?? 2;
  const tombstones = new Set((manifest.tombstones ?? []).map((t) => `${t[0]}:${t[1]}:${t[2]}`));

  console.log(`\nğŸ¯ Analyzing orders: [${orders.join(', ')}]`);

  const selected = new Set<IndexOrder>();
  const onlyPrimaries: Partial<Record<IndexOrder, number[]>> = {};
  const hot = await readHotness(`${dbPath}.pages`).catch(() => null);

  if (hot) {
    console.log(`ğŸ”¥ Hotness data loaded (updated: ${new Date(hot.updatedAt).toISOString()})`);
  } else {
    console.log(`ğŸ“ˆ No hotness data available`);
  }
  const getCountsForOrder = (order: IndexOrder) => {
    if (!hot) return {} as Record<string, number>;
    const a = hot.counts[order] ?? {};
    const pair: Partial<Record<IndexOrder, IndexOrder>> = {
      SPO: 'SOP',
      SOP: 'SPO',
      POS: 'PSO',
      PSO: 'POS',
      OSP: 'OPS',
      OPS: 'OSP',
    };
    const bKey = pair[order];
    if (!bKey) return a;
    const b = hot.counts[bKey] ?? {};
    const merged: Record<string, number> = { ...a };
    for (const [k, v] of Object.entries(b)) merged[k] = (merged[k] ?? 0) + v;
    return merged;
  };

  for (const order of orders) {
    console.log(`\nğŸ“‹ Analyzing order: ${order}`);
    const lookup = manifest.lookups.find((l) => l.order === order);
    if (!lookup || lookup.pages.length === 0) {
      console.log(`   âŒ No lookup or empty pages`);
      continue;
    }

    console.log(`   ğŸ“„ Total pages: ${lookup.pages.length}`);

    // ç»Ÿè®¡ primary â†’ é¡µæ•°
    const cnt = new Map<number, number>();
    for (const p of lookup.pages) cnt.set(p.primaryValue, (cnt.get(p.primaryValue) ?? 0) + 1);

    const multiPagePrimaries = [...cnt.entries()].filter(
      ([, pageCount]) => pageCount >= minMergePages,
    );
    const hasMergeCandidate = multiPagePrimaries.length > 0;

    console.log(`   ğŸ”— Unique primaries: ${cnt.size}`);
    console.log(
      `   ğŸ“Š Multi-page primaries (>=${minMergePages} pages): ${multiPagePrimaries.length}`,
    );

    if (hasMergeCandidate) {
      selected.add(order);
      console.log(`   âœ… Selected for compaction (merge candidates found)`);
      multiPagePrimaries.slice(0, 5).forEach(([primary, pageCount]) => {
        console.log(`      â€¢ Primary ${primary}: ${pageCount} pages`);
      });
      if (multiPagePrimaries.length > 5) {
        console.log(`      â€¢ ... and ${multiPagePrimaries.length - 5} more`);
      }
    }

    // ç®€åŒ–å¢“ç¢‘è§¦å‘ï¼šä»…ä¾æ®æœ‰æ—  tombstonesï¼ˆé˜ˆå€¼åœ¨ compaction å†…äºŒæ¬¡åˆ¤å®šï¼‰
    if (tombstones.size > 0) {
      if (!selected.has(order)) {
        selected.add(order);
        console.log(`   âœ… Selected for compaction (tombstone cleanup needed)`);
      } else {
        console.log(`   ğŸ“° Also has tombstones to clean`);
      }
    }

    // çƒ­åº¦é©±åŠ¨ï¼ˆå¢é‡æ¨¡å¼ï¼‰ï¼šé€‰å–çƒ­åº¦è¶…è¿‡é˜ˆå€¼ä¸”æ‹¥æœ‰å¤šé¡µçš„ primary
    if (options.mode !== 'rewrite' && hot && options.hotThreshold && options.hotThreshold > 0) {
      console.log(`   ğŸ”¥ Hot-based analysis (threshold: ${options.hotThreshold})`);
      const counts = getCountsForOrder(order);
      const candidates: Array<{ p: number; c: number; pages: number; score: number }> = [];
      const w = {
        hot: options.scoreWeights?.hot ?? 1,
        pages: options.scoreWeights?.pages ?? 1,
        tomb: options.scoreWeights?.tomb ?? 0.5,
      };
      const minScore = options.minScore ?? 1;

      console.log(`   ğŸ“Š Score weights: hot=${w.hot}, pages=${w.pages}, tomb=${w.tomb}`);
      console.log(`   ğŸ¯ Min score threshold: ${minScore}`);

      for (const [pval, count] of cnt.entries()) {
        if (count <= 1) continue; // éå¤šé¡µ
        const pvStr = String(pval);
        const hotCount = counts[pvStr] ?? 0;
        // è¯„åˆ†ï¼šçƒ­åº¦*wh + (é¡µæ•°-1)*wp + (tombstones>0?1:0)*wt
        const tombTerm = tombstones.size > 0 ? 1 : 0;
        const score = hotCount * w.hot + (count - 1) * w.pages + tombTerm * w.tomb;

        const scoreDetail = {
          primary: pval,
          hotness: hotCount,
          pageCount: count,
          fragmentation: count - 1,
          score: {
            hotness: hotCount * w.hot,
            pageCount: (count - 1) * w.pages,
            tombstone: tombTerm * w.tomb,
            total: score,
          },
        };

        if (hotCount >= options.hotThreshold && score >= minScore) {
          console.log(`   âœ… Primary ${pval} qualifies:`);
          console.log(`      â€¢ Hotness: ${hotCount} (score: +${scoreDetail.score.hotness})`);
          console.log(`      â€¢ Pages: ${count} (score: +${scoreDetail.score.pageCount})`);
          console.log(
            `      â€¢ Tombstone factor: ${tombTerm} (score: +${scoreDetail.score.tombstone})`,
          );
          console.log(`      â€¢ Total score: ${scoreDetail.score.total}`);
          console.log(`      â€¢ Action: INCLUDE`);
          console.log(
            `      â€¢ Reason: score >= ${minScore} AND hotness >= ${options.hotThreshold}`,
          );

          candidates.push({ p: pval, c: hotCount, pages: count, score });
        } else {
          const reasons = [];
          if (hotCount < options.hotThreshold)
            reasons.push(`hotness ${hotCount} < ${options.hotThreshold}`);
          if (score < minScore) reasons.push(`score ${score} < ${minScore}`);

          console.log(`   âŒ Primary ${pval} excluded:`);
          console.log(`      â€¢ Hotness: ${hotCount}`);
          console.log(`      â€¢ Pages: ${count}`);
          console.log(`      â€¢ Total score: ${scoreDetail.score.total}`);
          console.log(`      â€¢ Action: SKIP`);
          console.log(`      â€¢ Reason: ${reasons.join(' AND ')}`);
        }
      }

      // ä¼˜å…ˆæŒ‰åˆ†æ•°ã€å†æŒ‰çƒ­åº¦æ’åº
      const sorted = candidates.sort((a, b) => b.score - a.score || b.c - a.c);
      const topK = options.maxPrimariesPerOrder
        ? sorted.slice(0, options.maxPrimariesPerOrder)
        : sorted;

      if (topK.length > 0) {
        console.log(`   ğŸ¯ Top ${topK.length} hot primaries selected:`);
        topK.forEach((c, i) => {
          console.log(
            `      ${i + 1}. Primary ${c.p}: hotness=${c.c}, pages=${c.pages}, score=${c.score}`,
          );
        });

        (onlyPrimaries as any)[order] = topK.map((x) => x.p);
        if (!selected.has(order)) {
          selected.add(order);
          console.log(`   âœ… Selected for compaction (hot primaries found)`);
        }
      } else {
        console.log(`   âŒ No hot primaries qualify for incremental compaction`);
      }
    }
  }

  let selectedOrders = [...selected];

  console.log(`\nğŸ“ˆ LSM segment analysis:`);
  // è¯„ä¼°æ˜¯å¦å¹¶å…¥ LSM æ®µ
  let includeLsmSegments = options.includeLsmSegments ?? false;
  if (!includeLsmSegments && options.includeLsmSegmentsAuto) {
    try {
      const buf = await fsp.readFile(`${dbPath}.pages/lsm-manifest.json`);
      const lsm = JSON.parse(buf.toString('utf8')) as { segments: Array<{ count?: number }> };
      const segs = lsm.segments?.length ?? 0;
      const triples = (lsm.segments ?? []).reduce((a, s) => a + (s.count ?? 0), 0);
      const segTh = options.lsmSegmentsThreshold ?? 1;
      const triTh = options.lsmTriplesThreshold ?? options.pageSize ?? manifest.pageSize ?? 1024;

      console.log(`   ğŸ“Š LSM segments: ${segs}`);
      console.log(`   ğŸ“Š LSM triples: ${triples}`);
      console.log(`   ğŸ¯ Thresholds: segments >= ${segTh}, triples >= ${triTh}`);

      if (segs >= segTh || triples >= triTh) {
        includeLsmSegments = true;
        console.log(`   âœ… Will include LSM segments in compaction`);
        const reasons = [];
        if (segs >= segTh) reasons.push(`segments ${segs} >= ${segTh}`);
        if (triples >= triTh) reasons.push(`triples ${triples} >= ${triTh}`);
        console.log(`   ğŸ“‹ Reason: ${reasons.join(' OR ')}`);
      } else {
        console.log(`   âŒ LSM segments below threshold - excluding`);
      }
    } catch {
      console.log(`   âš ï¸  No LSM manifest found - skipping LSM analysis`);
    }
  } else if (includeLsmSegments) {
    console.log(`   âœ… LSM segments explicitly included`);
  } else {
    console.log(`   âŒ LSM segments not requested`);
  }

  if (selectedOrders.length === 0 && includeLsmSegments && !dryRun) {
    // å½“ä»…å› ä¸º LSM æ®µéœ€è¦å¹¶å…¥æ—¶ï¼Œè‡³å°‘å¯¹æŒ‡å®š orders æ‰§è¡Œä¸€æ¬¡åˆå¹¶
    console.log(`\nğŸ”„ No orders selected but LSM merge needed - selecting all orders`);
    selectedOrders = orders;
  }

  console.log(`\nğŸ¯ Final compaction decision:`);
  console.log(`   Selected orders: [${selectedOrders.join(', ')}]`);
  console.log(`   Include LSM segments: ${includeLsmSegments}`);
  console.log(`   Dry run: ${dryRun}`);

  if (selectedOrders.length === 0) {
    console.log(`\nâœ… No compaction needed - all indexes are optimal`);
    return { selectedOrders };
  }

  const compactOpts: CompactOptions = {
    orders: selectedOrders,
    pageSize: options.pageSize ?? manifest.pageSize,
    minMergePages,
    tombstoneRatioThreshold: options.tombstoneRatioThreshold,
    compression: options.compression ?? manifest.compression,
    hotCompression: options.hotCompression,
    coldCompression: options.coldCompression,
    dryRun,
    mode: options.mode ?? 'incremental',
    onlyPrimaries,
    includeLsmSegments,
  };

  console.log(`\nğŸš€ Starting compaction...`);
  const stats = await compactDatabase(dbPath, compactOpts);

  console.log(`\nğŸ“Š Compaction completed:`);
  console.log(`   Pages before: ${stats.pagesBefore ?? 0}`);
  console.log(`   Pages after: ${stats.pagesAfter ?? 0}`);
  console.log(`   Primaries merged: ${stats.primariesMerged ?? 0}`);
  console.log(`   Removed by tombstones: ${stats.removedByTombstones ?? 0}`);
  if (stats.ordersRewritten) {
    console.log(`   Orders processed: [${stats.ordersRewritten.join(', ')}]`);
  }

  if (options.autoGC && !dryRun) {
    console.log(`\nğŸ—‘ï¸  Running auto garbage collection...`);
    await garbageCollectPages(dbPath, { dryRun: false });
    console.log(`âœ… Garbage collection completed`);
  } else if (options.autoGC && dryRun) {
    console.log(`\nâ„¹ï¸  Auto GC skipped (dry-run mode)`);
  }

  console.log(`\nâœ… Auto-compact finished successfully`);
  return { selectedOrders, compact: stats };
}
