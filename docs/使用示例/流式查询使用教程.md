# 流式查询使用教程

## 目标

- 深入理解 `streamFacts` 与 `QueryBuilder.stream` 的使用场景与性能特性
- 构建稳定的流式处理管道

## 何时使用 Streaming

- 结果集很大（>10 万条），无法一次全部加载到内存
- 需要边读取边处理（写日志、推送队列、计算统计）
- 与异步任务配合，例如 ETL 或实时监控

## 基础模式

```ts
for await (const batch of db.streamFacts({ predicate: 'FRIEND_OF' }, 512)) {
  await processBatch(batch);
}
```

- `batchSize` 影响内存与吞吐，默认 256
- `processBatch` 中可进行异步操作

## 链式 Streaming

```ts
for await (const edges of db
  .find({ predicate: 'FRIEND_OF' })
  .whereProperty('strength', '>=', 0.6, 'edge')
  .batch(128)) {
  await sendToQueue(edges);
}
```

## 背压控制

- 使用消息队列：`await queue.add(batch)`
- 使用 Node.js 流：`Readable.from(iterator)` + `pipe`
- 人工节流：`if (pending > limit) await sleep(10)`

## 错误处理

```ts
try {
  for await (const batch of iterator) {
    await process(batch);
  }
} catch (err) {
  console.error('stream error', err);
}
```

- 若处理中抛错，流会终止
- 可使用 `retry` 机制重启流

## 与快照结合

```ts
await db.withSnapshot(async (snap) => {
  // 快照内 find() 回落为即刻物化，若需严格流式，建议使用底层 streamFacts
  for await (const batch of snap.streamFacts({ predicate: 'FRIEND_OF' }, 256)) {
    await process(batch);
  }
});
```

## 性能提示

| 项目      | 建议                                                    |
| --------- | ------------------------------------------------------- |
| batchSize | 128~1024，根据内存与消费者速度调整                      |
| 并发      | 可在 `processBatch` 中使用 Promise.all 处理批次内部数据 |
| 日志      | 每处理一定批次输出一次，避免日志爆炸                    |

## 示例：导出 CSV

```ts
import { createWriteStream } from 'node:fs';
const out = createWriteStream('result.csv');
out.write('subject,predicate,object\n');

for await (const batch of db.streamFacts({}, 512)) {
  for (const fact of batch) {
    out.write(`${fact.subject},${fact.predicate},${fact.object}\n`);
  }
}

out.end();
```

## 延伸阅读

- [示例 06 · 流式查询与大结果](06-流式查询与大结果-示例.md)
- [教程 03 · 查询与链式联想](../教学文档/教程-03-查询与链式联想.md)
